{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07327a6-67bd-44a5-a82a-ab485950029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Sequence, Tuple\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import explain\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba9fce9-fd90-4602-94a3-9af98eb182bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id='ihr-vertex-pipelines'\n",
    "my_region='europe-west4' # :flag-nl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed852e-8d78-43b3-be82-52268c8821df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_model(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    display_name: str,\n",
    "    serving_container_image_uri: str,\n",
    "    artifact_uri: Optional[str] = None,\n",
    "    serving_container_predict_route: Optional[str] = None,\n",
    "    serving_container_health_route: Optional[str] = None,\n",
    "    description: Optional[str] = None,\n",
    "    serving_container_command: Optional[Sequence[str]] = None,\n",
    "    serving_container_args: Optional[Sequence[str]] = None,\n",
    "    serving_container_environment_variables: Optional[Dict[str, str]] = None,\n",
    "    serving_container_ports: Optional[Sequence[int]] = None,\n",
    "    instance_schema_uri: Optional[str] = None,\n",
    "    parameters_schema_uri: Optional[str] = None,\n",
    "    prediction_schema_uri: Optional[str] = None,\n",
    "    explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n",
    "    explanation_parameters: Optional[explain.ExplanationParameters] = None,\n",
    "    sync: bool = True,\n",
    "):\n",
    "\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=display_name,\n",
    "        artifact_uri=artifact_uri,\n",
    "        serving_container_image_uri=serving_container_image_uri,\n",
    "        serving_container_predict_route=serving_container_predict_route,\n",
    "        serving_container_health_route=serving_container_health_route,\n",
    "        instance_schema_uri=instance_schema_uri,\n",
    "        parameters_schema_uri=parameters_schema_uri,\n",
    "        prediction_schema_uri=prediction_schema_uri,\n",
    "        description=description,\n",
    "        serving_container_command=serving_container_command,\n",
    "        serving_container_args=serving_container_args,\n",
    "        serving_container_environment_variables=serving_container_environment_variables,\n",
    "        serving_container_ports=serving_container_ports,\n",
    "        explanation_metadata=explanation_metadata,\n",
    "        explanation_parameters=explanation_parameters,\n",
    "        sync=sync,\n",
    "    )\n",
    "\n",
    "    model.wait()\n",
    "\n",
    "    print(model.display_name)\n",
    "    print(model.resource_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d46315-cc3d-4482-8fd2-ed9183cf2ddb",
   "metadata": {},
   "source": [
    "## Upload and deploy raw model\n",
    "\n",
    "This is just a raw deploy of the `saved_model.pb`, so using this model requires using the transformed data in TF-IDF format (or whatever the model was trained with). What we want is a model that takes the text of a review. This requires:\n",
    "\n",
    "* Including the `transform_fn` somehow\n",
    "* Probably [specifying schemas](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models?&_ga=2.51426537.-1793164395.1642757755#predictschemata), predict route? Deploying a custom container?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03340999-ddb3-4f63-b5fc-d20b6301ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = upload_model(\n",
    "    project=project_id,\n",
    "    location=my_region,\n",
    "    display_name='my first model',\n",
    "    serving_container_image_uri='europe-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest',\n",
    "    artifact_uri='gs://ihr-vertex-pipelines/0.13+11.gbee0168/batch=8192/epochs=15/model/saved_model/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814509bb-c384-4889-938d-3464c474eb7d",
   "metadata": {},
   "source": [
    "Check out deployed models: [deployed models in console](https://pantheon2.corp.google.com/vertex-ai/models?project=ihr-vertex-pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c782d4-9e35-4bdc-aad0-ba71d26b0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_endpoint(\n",
    "    project: str, display_name: str, location: str,\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name=display_name, project=project, location=my_region,\n",
    "    )\n",
    "\n",
    "    print(endpoint.display_name)\n",
    "    print(endpoint.resource_name)\n",
    "    return endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134370ea-b4e2-4903-b529-91defd5a99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = create_endpoint(project_id, 'raw_model_endpoint', my_region)\n",
    "endpoint_id = endpoint.resource_name.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e3548-b74e-4c8b-abdd-ef8902b69c64",
   "metadata": {},
   "source": [
    "Check out model endpoints: [model endpoints in console](https://pantheon2.corp.google.com/vertex-ai/endpoints?project=ihr-vertex-pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f7f144-9fbe-4921-bc17-85d9832ddb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9f2d0-af40-48d1-ad7e-6faa48436469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model_with_dedicated_resources(\n",
    "    project,\n",
    "    location,\n",
    "    model_name: str,\n",
    "    machine_type: str,\n",
    "    endpoint: Optional[aiplatform.Endpoint] = None,\n",
    "    deployed_model_display_name: Optional[str] = None,\n",
    "    traffic_percentage: Optional[int] = 0,\n",
    "    traffic_split: Optional[Dict[str, int]] = None,\n",
    "    min_replica_count: int = 1,\n",
    "    max_replica_count: int = 1,\n",
    "    accelerator_type: Optional[str] = None,\n",
    "    accelerator_count: Optional[int] = None,\n",
    "    explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n",
    "    explanation_parameters: Optional[explain.ExplanationParameters] = None,\n",
    "    metadata: Optional[Sequence[Tuple[str, str]]] = (),\n",
    "    sync: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "        model_name: A fully-qualified model resource name or model ID.\n",
    "              Example: \"projects/123/locations/us-central1/models/456\" or\n",
    "              \"456\" when project and location are initialized or passed.\n",
    "    \"\"\"\n",
    "\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    model = aiplatform.Model(model_name=model_name)\n",
    "\n",
    "    # The explanation_metadata and explanation_parameters should only be\n",
    "    # provided for a custom trained model and not an AutoML model.\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        deployed_model_display_name=deployed_model_display_name,\n",
    "        traffic_percentage=traffic_percentage,\n",
    "        traffic_split=traffic_split,\n",
    "        machine_type=machine_type,\n",
    "        min_replica_count=min_replica_count,\n",
    "        max_replica_count=max_replica_count,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        explanation_metadata=explanation_metadata,\n",
    "        explanation_parameters=explanation_parameters,\n",
    "        metadata=metadata,\n",
    "        sync=sync, # Whether to execute this method synchronously\n",
    "    )\n",
    "\n",
    "    model.wait()\n",
    "\n",
    "    print(model.display_name)\n",
    "    print(model.resource_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9615490-2ab1-4439-81bd-ba4289a0c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model = deploy_model_with_dedicated_resources(project_id, my_region, model.resource_name, 'n1-standard-4', endpoint, traffic_percentage=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818ce56-7153-4b8e-9581-5b476c6adb05",
   "metadata": {},
   "source": [
    "## Get some predictions from the deployed model using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44b726ce-7172-4110-b87d-b4ae399a4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpoint_predict(\n",
    "    project: str, location: str, instances: list, endpoint: str\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint(endpoint)\n",
    "\n",
    "    prediction = endpoint.predict(instances=instances)\n",
    "    print(prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38fc1cde-3b65-49b7-bb3e-ecfd4f79cb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 12:27:49.914697: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-01-25 12:27:49.914735: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-25 12:27:49.914768: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vm-7f3e4f9c-1f26-48e8-9195-c899f55e78bc): /proc/driver/nvidia/version does not exist\n",
      "2022-01-25 12:27:49.915091: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = 'gs://ihr-vertex-pipelines/data/prepared/test/test_data-00000-of-00001.tfrecord'\n",
    "raw_dataset = tf.data.TFRecordDataset([testdata])\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d591f490-5c6e-4cdb-990c-5491a0e14288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tf_record(record):\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(raw_record.numpy())\n",
    "  return example\n",
    "\n",
    "raw_instances = [parse_tf_record(raw_record) for raw_record in raw_dataset.take(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f13c4c41-e974-4868-89a8-7c62edb06ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'************* SPOILERS BELOW ************* \"\\'Night, Mother\" is the story of Jesse (Sissy Spacek), a divorced epileptic woman who calmly announces to her brash mother (Anne Bancroft) that she\\'s going to commit suicide. This is a fascinating premise that is drained of all vitality and excitement. The brilliant hook turns out to be a cheat- the story that follows is lacking in substance, gravity and revelatory value. Where are the shocks and surprises as mother and daughter have what may be the last conversation of their lives? Where are the secrets revealed, the confessions and fantasies and regrets? They\\'re here, but they\\'ve all been painted the same dull color that keeps emotion in the background and celebrates the \\'genius\\' of playwright Marsha Norman at the expense of everything else. The result is not a film but an exhausting endurance test.<br /><br />Let me preface my comments by saying I find Sissy Spacek to be one of the greatest actresses in the history of motion pictures, a woman so magnetic, so natural that she continues to surprise and amaze me after twenty years of stardom. She brings a touch of class and magic to everything she does, and I\\'ve seen her rescue more than one film from the recycling bin with her angelic face and vulnerable eyes, her soft voice and sweet smile. It was because of the great Spacek that I watched this film in the first place, and for one of her movies to be terrible it has to fail in a significant way. This film fails in two.<br /><br />First and foremost the film is adapted so faithfully from the Pulitzer-winning stage play that it is claustrophobic and repetitive. The entire movie is a two-woman dialogue between Jesse and her Mother. What worked on stage- a middle-aged mother and daughter argue for two hours in small house- dies on film. A play, no matter how great, needs to be *adapted* for the screen\\xc2\\x85 it is self-indulgent and arrogant to believe that the dialogue is so perfect that not of a word of it can be altered. The screenplay for this film could have been shortened by thirty to forty pages, and a knowing screenwriter would have given the brilliant Spacek and competent Bancroft some *physical* sequences, some facial reactions, something to break up the wall-to-wall yak fest and prison-like single-set. It is no wonder that the screenplay was adapted by the original playwright Marsha Norman, who may know theater but reveals herself here to be clueless in film.<br /><br />I cannot over-emphasize the effect the stage-play script has on the film. Watching Jesse and her Mother argue about Jesse\\'s impending suicide is redundant and dull. The women walk from the living room into the kitchen into the den and back into the living room, where they start all over again. A tiny Midwestern house is not the ideal location for a single-set film, and the director never tries anything clever or original, never tries to break up the monotony with an exterior shot or cutaway or a flashback or *anything*. There\\'s no music, no other characters, no other stories... just two women covering the couch cushions and arguing their opinions. The reverence given to the play is sickening\\xc2\\x85 even Shakespeare\\'s most solemn classics get shaken up for the screen. The commitment to the original play seems almost spiteful\\xc2\\x85 it\\'s as if the film was made only to document the dramatic treasure that was the stage play, with the audience an afterthought.<br /><br />The other reason the film fails is Anne Bancroft. She may be a good stage actress but on film- where presence is 80% of performance- she rarely seems to fit. She certainly doesn\\'t fit here, playing a Midwestern grandmother but looking more like Mrs. Robinson before her morning coffee. She chases Jesse around the house, looking more aggravated than astounded, and seems extraordinarily unsympathetic, even when her lines convey a loving- if flawed- woman.<br /><br />Sissy Spacek is great as she always is, honest and open and so good that you actually understand and agree with her character\\'s choice. Sissy lets us see that Jesse is a flat tire, a wrong turn of a woman who has had every bad break and made too many wrong choices. She\\'s never had control of her life, and her suicide will be her way of finally saying \"No more- this is where I get off.\" That\\'s how she puts it anyway, and when Spacek speaks\\xc2\\x85 you listen. She proves in all her films that a good actress doesn\\'t have to behave like a man, doesn\\'t have to be all bluff and bravado and borrowed testosterone. In this and in films like \"Coal Miner\\'s Daughter\" she quietly demonstrates a soft strength and quiet depth that is as impressive as it is hypnotic\\xc2\\x85 you can\\'t help but fall in love.<br /><br />That\\'s why it was so hard for me to watch \"\\'Night, Mother.\" Spacek is wasted in a stilted stunt of a film that never serves to engage or even distract. I would not recommend this movie to anyone except die-hard fans of Sissy like myself and even then you\\'ll be disappointed. I do give the film an entire letter grade bonus for the ending, which is courageous enough to let the lead character do what\\'s right for *her* and not pander to a hackneyed happy ending. GRADE: C'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_instances[0].features.feature['text'].bytes_list.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14a9612e-0958-4803-85bf-6bb1efe26fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_instance(raw_record, key):\n",
    "    text_bytes = raw_record.features.feature['text'].bytes_list.value[0]\n",
    "    return { 'values': text_bytes, 'key': key }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a234083-512f-40ba-860f-c892284f6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = {'instances': [to_instance(v, k) for k, v in enumerate(raw_instances)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ad68684-421a-4616-b52d-0469ef9cc9c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 {\n    \"error\": \"Failed to process element: 0 of 'instances' list. Error: INVALID_ARGUMENT: JSON Value: \\\"instances\\\" Type: String is not of expected type: float\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    945\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"{\n    \"error\": \"Failed to process element: 0 of 'instances' list. Error: INVALID_ARGUMENT: JSON Value: \\\"instances\\\" Type: String is not of expected type: float\"\n}\"\n\tdebug_error_string = \"{\"created\":\"@1643131114.747422369\",\"description\":\"Error received from peer ipv4:64.233.191.95:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1063,\"grpc_message\":\"{\\n    \"error\": \"Failed to process element: 0 of 'instances' list. Error: INVALID_ARGUMENT: JSON Value: \\\"instances\\\" Type: String is not of expected type: float\"\\n}\",\"grpc_status\":3}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1/339589078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mendpoint_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'5446488022793060352'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_region\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1/2697265285.py\u001b[0m in \u001b[0;36mendpoint_predict\u001b[0;34m(project, location, instances, endpoint)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maiplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEndpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, instances, parameters)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         prediction_response = self._prediction_client.predict(\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m         )\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Done; return the response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 {\n    \"error\": \"Failed to process element: 0 of 'instances' list. Error: INVALID_ARGUMENT: JSON Value: \\\"instances\\\" Type: String is not of expected type: float\"\n}"
     ]
    }
   ],
   "source": [
    "endpoint_id = '5446488022793060352'\n",
    "pred = endpoint_predict(project_id, my_region, instances, endpoint_id)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b9161-37b1-4117-b31b-13c08f78826b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "managed-notebooks.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu:latest"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
