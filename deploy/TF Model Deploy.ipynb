{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c07327a6-67bd-44a5-a82a-ab485950029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Sequence, Tuple\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import explain\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization\n",
    "from keras.models import load_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3ba9fce9-fd90-4602-94a3-9af98eb182bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id='ihr-vertex-pipelines'\n",
    "my_region='europe-west4' # :flag-nl:\n",
    "model_name='model_text_jan27'\n",
    "endpoint_name='raw_model_endpoint'\n",
    "model_location='gs://ihr-vertex-pipelines/0.13+14.gb9a60f7/batch=8192/epochs=15/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ed852e-8d78-43b3-be82-52268c8821df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_model(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    display_name: str,\n",
    "    serving_container_image_uri: str,\n",
    "    artifact_uri: Optional[str] = None,\n",
    "    serving_container_predict_route: Optional[str] = None,\n",
    "    serving_container_health_route: Optional[str] = None,\n",
    "    description: Optional[str] = None,\n",
    "    serving_container_command: Optional[Sequence[str]] = None,\n",
    "    serving_container_args: Optional[Sequence[str]] = None,\n",
    "    serving_container_environment_variables: Optional[Dict[str, str]] = None,\n",
    "    serving_container_ports: Optional[Sequence[int]] = None,\n",
    "    instance_schema_uri: Optional[str] = None,\n",
    "    parameters_schema_uri: Optional[str] = None,\n",
    "    prediction_schema_uri: Optional[str] = None,\n",
    "    explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n",
    "    explanation_parameters: Optional[explain.ExplanationParameters] = None,\n",
    "    sync: bool = True,\n",
    "):\n",
    "\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=display_name,\n",
    "        artifact_uri=artifact_uri,\n",
    "        serving_container_image_uri=serving_container_image_uri,\n",
    "        serving_container_predict_route=serving_container_predict_route,\n",
    "        serving_container_health_route=serving_container_health_route,\n",
    "        instance_schema_uri=instance_schema_uri,\n",
    "        parameters_schema_uri=parameters_schema_uri,\n",
    "        prediction_schema_uri=prediction_schema_uri,\n",
    "        description=description,\n",
    "        serving_container_command=serving_container_command,\n",
    "        serving_container_args=serving_container_args,\n",
    "        serving_container_environment_variables=serving_container_environment_variables,\n",
    "        serving_container_ports=serving_container_ports,\n",
    "        explanation_metadata=explanation_metadata,\n",
    "        explanation_parameters=explanation_parameters,\n",
    "        sync=sync,\n",
    "    )\n",
    "\n",
    "    model.wait()\n",
    "\n",
    "    print(model.display_name)\n",
    "    print(model.resource_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d46315-cc3d-4482-8fd2-ed9183cf2ddb",
   "metadata": {},
   "source": [
    "## Upload and deploy raw model\n",
    "\n",
    "This is just a raw deploy of the `saved_model.pb`, so using this model requires using the transformed data in TF-IDF format (or whatever the model was trained with). What we want is a model that takes the text of a review. This requires:\n",
    "\n",
    "* Including the `transform_fn` somehow\n",
    "* Probably [specifying schemas](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models?&_ga=2.51426537.-1793164395.1642757755#predictschemata), predict route? Deploying a custom container?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03340999-ddb3-4f63-b5fc-d20b6301ef8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n",
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/237148598933/locations/europe-west4/models/2258080224103104512/operations/3153930412577783808\n",
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/237148598933/locations/europe-west4/models/2258080224103104512\n",
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/237148598933/locations/europe-west4/models/2258080224103104512')\n",
      "model_text_jan27\n",
      "projects/237148598933/locations/europe-west4/models/2258080224103104512\n"
     ]
    }
   ],
   "source": [
    "model = upload_model(\n",
    "    project=project_id,\n",
    "    location=my_region,\n",
    "    display_name=model_name,\n",
    "    serving_container_image_uri='europe-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest',\n",
    "    artifact_uri=model_location + '/saved_model/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814509bb-c384-4889-938d-3464c474eb7d",
   "metadata": {},
   "source": [
    "Check out deployed models: [deployed models in console](https://pantheon2.corp.google.com/vertex-ai/models?project=ihr-vertex-pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c782d4-9e35-4bdc-aad0-ba71d26b0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_endpoint(\n",
    "    project: str, display_name: str, location: str,\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name=display_name, project=project, location=my_region,\n",
    "    )\n",
    "\n",
    "    print(endpoint.display_name)\n",
    "    print(endpoint.resource_name)\n",
    "    return endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134370ea-b4e2-4903-b529-91defd5a99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create it\n",
    "endpoint = create_endpoint(project_id, endpoint_name, my_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1dd63cd-8e29-46b0-8ba2-d0405bd75565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or get an existing one\n",
    "endpoint = aiplatform.Endpoint('5446488022793060352')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12aa536c-0d0a-4910-8821-d88dedca983c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5446488022793060352'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_id = endpoint.resource_name.split('/')[-1]\n",
    "endpoint_id\n",
    "#endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e3548-b74e-4c8b-abdd-ef8902b69c64",
   "metadata": {},
   "source": [
    "Check out model endpoints: [model endpoints in console](https://pantheon2.corp.google.com/vertex-ai/endpoints?project=ihr-vertex-pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bed9f2d0-af40-48d1-ad7e-6faa48436469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model_with_dedicated_resources(\n",
    "    project,\n",
    "    location,\n",
    "    model_name: str,\n",
    "    machine_type: str,\n",
    "    endpoint: Optional[aiplatform.Endpoint] = None,\n",
    "    deployed_model_display_name: Optional[str] = None,\n",
    "    traffic_percentage: Optional[int] = 0,\n",
    "    traffic_split: Optional[Dict[str, int]] = None,\n",
    "    min_replica_count: int = 1,\n",
    "    max_replica_count: int = 1,\n",
    "    accelerator_type: Optional[str] = None,\n",
    "    accelerator_count: Optional[int] = None,\n",
    "    explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n",
    "    explanation_parameters: Optional[explain.ExplanationParameters] = None,\n",
    "    metadata: Optional[Sequence[Tuple[str, str]]] = (),\n",
    "    sync: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "        model_name: A fully-qualified model resource name or model ID.\n",
    "              Example: \"projects/123/locations/us-central1/models/456\" or\n",
    "              \"456\" when project and location are initialized or passed.\n",
    "    \"\"\"\n",
    "\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    model = aiplatform.Model(model_name=model_name)\n",
    "\n",
    "    # The explanation_metadata and explanation_parameters should only be\n",
    "    # provided for a custom trained model and not an AutoML model.\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        deployed_model_display_name=deployed_model_display_name,\n",
    "        traffic_percentage=traffic_percentage,\n",
    "        traffic_split=traffic_split,\n",
    "        machine_type=machine_type,\n",
    "        min_replica_count=min_replica_count,\n",
    "        max_replica_count=max_replica_count,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        explanation_metadata=explanation_metadata,\n",
    "        explanation_parameters=explanation_parameters,\n",
    "        metadata=metadata,\n",
    "        sync=sync, # Whether to execute this method synchronously\n",
    "    )\n",
    "\n",
    "    model.wait()\n",
    "\n",
    "    print(model.display_name)\n",
    "    print(model.resource_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44141ae7-410e-4c0a-a123-36f3529e73be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_text_jan27'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f76aea4a-f908-4c4f-ad90-cca7bd7eeb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Model object at 0x7f0004502ed0> \n",
       "resource name: projects/237148598933/locations/europe-west4/models/2258080224103104512"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9615490-2ab1-4439-81bd-ba4289a0c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/237148598933/locations/europe-west4/endpoints/5446488022793060352\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/237148598933/locations/europe-west4/endpoints/5446488022793060352/operations/5081471053092356096\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/237148598933/locations/europe-west4/endpoints/5446488022793060352\n",
      "model_text_jan27\n",
      "projects/237148598933/locations/europe-west4/models/2258080224103104512\n"
     ]
    }
   ],
   "source": [
    "deployed_model = deploy_model_with_dedicated_resources(\n",
    "    project_id, \n",
    "    my_region, \n",
    "    model.resource_name, \n",
    "    'n1-standard-4', \n",
    "    endpoint, \n",
    "    traffic_percentage=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818ce56-7153-4b8e-9581-5b476c6adb05",
   "metadata": {},
   "source": [
    "## Get some predictions from the deployed model using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44b726ce-7172-4110-b87d-b4ae399a4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpoint_predict(\n",
    "    project: str, location: str, instances: list, endpoint: str\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint(endpoint)\n",
    "\n",
    "    prediction = endpoint.predict(instances=instances)\n",
    "    print(prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "491615d2-293b-4d84-8294-24324dfceb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None,),\n",
       " 'dtype': 'string',\n",
       " 'max_tokens': 20000,\n",
       " 'standardize': 'lower_and_strip_punctuation',\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': 2,\n",
       " 'output_mode': 'multi_hot',\n",
       " 'output_sequence_length': None,\n",
       " 'pad_to_max_tokens': False,\n",
       " 'sparse': False,\n",
       " 'ragged': False,\n",
       " 'vocabulary': None,\n",
       " 'idf_weights': None}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_model = load_model(model_location + '/vectorizer/')\n",
    "restored_vectorizer = restored_model.layers[0]\n",
    "restored_vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "38fc1cde-3b65-49b7-bb3e-ecfd4f79cb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = 'gs://ihr-vertex-pipelines/data/prepared/test/test_data-00000-of-00001.tfrecord'\n",
    "raw_dataset = tf.data.TFRecordDataset([testdata])\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5c50557b-2372-4436-8cc1-f994fc44afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20000), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"my-kschool-model\" (type Functional).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1/475478522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkerasmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored_vectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"my-kschool-model\" (type Functional).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# not sure why this doesn't work\n",
    "kerasmodel.predict(raw_dataset.map(restored_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bc09254d-3e07-4ef7-8f1b-3ce7d46dc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to numpy and that works\n",
    "instances = np.array([x.numpy() for x in raw_dataset.map(restored_vectorizer).take(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9353dd0b-91f1-4abd-acc4-04ff87f3536e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09841356],\n",
       "       [0.37950382],\n",
       "       [0.24578968],\n",
       "       [0.16459799],\n",
       "       [0.36051244]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasmodel.predict(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2ad68684-421a-4616-b52d-0469ef9cc9c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce value: array([1., 1., 1., ..., 0., 0., 0.], dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1/339589078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mendpoint_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'5446488022793060352'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_region\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1/2697265285.py\u001b[0m in \u001b[0;36mendpoint_predict\u001b[0;34m(project, location, instances, endpoint)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maiplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEndpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, instances, parameters)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         prediction_response = self._prediction_client.predict(\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m         )\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minstances\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                 \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/_collections_abc.py\u001b[0m in \u001b[0;36mextend\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;34m'S.extend(iterable) -- extend sequence by appending elements from the iterable'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/_collections_abc.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;34m'S.append(value) -- append value to the end of the sequence'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proto/marshal/collections/repeated.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, index, value)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;34m\"\"\"Insert ``value`` in the sequence before ``index``.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mpb_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_marshal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pb_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proto/marshal/marshal.py\u001b[0m in \u001b[0;36mto_proto\u001b[0;34m(self, proto_type, value, strict)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;31m# Convert ordinary values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mrule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_noop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mpb_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# Sanity check: If we are in strict mode, did we get the value we want?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/helpers/_decorators.py\u001b[0m in \u001b[0;36mto_proto\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proto/marshal/rules/struct.py\u001b[0m in \u001b[0;36mto_proto\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mstruct_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_marshal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStruct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             )\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to coerce value: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to coerce value: array([1., 1., 1., ..., 0., 0., 0.], dtype=float32)"
     ]
    }
   ],
   "source": [
    "# but then why doesn't this?\n",
    "endpoint_id = '5446488022793060352'\n",
    "pred = endpoint_predict(project_id, my_region, instances, endpoint_id)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f13c4c41-e974-4868-89a8-7c62edb06ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'************* SPOILERS BELOW ************* \"\\'Night, Mother\" is the story of Jesse (Sissy Spacek), a divorced epileptic woman who calmly announces to her brash mother (Anne Bancroft) that she\\'s going to commit suicide. This is a fascinating premise that is drained of all vitality and excitement. The brilliant hook turns out to be a cheat- the story that follows is lacking in substance, gravity and revelatory value. Where are the shocks and surprises as mother and daughter have what may be the last conversation of their lives? Where are the secrets revealed, the confessions and fantasies and regrets? They\\'re here, but they\\'ve all been painted the same dull color that keeps emotion in the background and celebrates the \\'genius\\' of playwright Marsha Norman at the expense of everything else. The result is not a film but an exhausting endurance test.<br /><br />Let me preface my comments by saying I find Sissy Spacek to be one of the greatest actresses in the history of motion pictures, a woman so magnetic, so natural that she continues to surprise and amaze me after twenty years of stardom. She brings a touch of class and magic to everything she does, and I\\'ve seen her rescue more than one film from the recycling bin with her angelic face and vulnerable eyes, her soft voice and sweet smile. It was because of the great Spacek that I watched this film in the first place, and for one of her movies to be terrible it has to fail in a significant way. This film fails in two.<br /><br />First and foremost the film is adapted so faithfully from the Pulitzer-winning stage play that it is claustrophobic and repetitive. The entire movie is a two-woman dialogue between Jesse and her Mother. What worked on stage- a middle-aged mother and daughter argue for two hours in small house- dies on film. A play, no matter how great, needs to be *adapted* for the screen\\xc2\\x85 it is self-indulgent and arrogant to believe that the dialogue is so perfect that not of a word of it can be altered. The screenplay for this film could have been shortened by thirty to forty pages, and a knowing screenwriter would have given the brilliant Spacek and competent Bancroft some *physical* sequences, some facial reactions, something to break up the wall-to-wall yak fest and prison-like single-set. It is no wonder that the screenplay was adapted by the original playwright Marsha Norman, who may know theater but reveals herself here to be clueless in film.<br /><br />I cannot over-emphasize the effect the stage-play script has on the film. Watching Jesse and her Mother argue about Jesse\\'s impending suicide is redundant and dull. The women walk from the living room into the kitchen into the den and back into the living room, where they start all over again. A tiny Midwestern house is not the ideal location for a single-set film, and the director never tries anything clever or original, never tries to break up the monotony with an exterior shot or cutaway or a flashback or *anything*. There\\'s no music, no other characters, no other stories... just two women covering the couch cushions and arguing their opinions. The reverence given to the play is sickening\\xc2\\x85 even Shakespeare\\'s most solemn classics get shaken up for the screen. The commitment to the original play seems almost spiteful\\xc2\\x85 it\\'s as if the film was made only to document the dramatic treasure that was the stage play, with the audience an afterthought.<br /><br />The other reason the film fails is Anne Bancroft. She may be a good stage actress but on film- where presence is 80% of performance- she rarely seems to fit. She certainly doesn\\'t fit here, playing a Midwestern grandmother but looking more like Mrs. Robinson before her morning coffee. She chases Jesse around the house, looking more aggravated than astounded, and seems extraordinarily unsympathetic, even when her lines convey a loving- if flawed- woman.<br /><br />Sissy Spacek is great as she always is, honest and open and so good that you actually understand and agree with her character\\'s choice. Sissy lets us see that Jesse is a flat tire, a wrong turn of a woman who has had every bad break and made too many wrong choices. She\\'s never had control of her life, and her suicide will be her way of finally saying \"No more- this is where I get off.\" That\\'s how she puts it anyway, and when Spacek speaks\\xc2\\x85 you listen. She proves in all her films that a good actress doesn\\'t have to behave like a man, doesn\\'t have to be all bluff and bravado and borrowed testosterone. In this and in films like \"Coal Miner\\'s Daughter\" she quietly demonstrates a soft strength and quiet depth that is as impressive as it is hypnotic\\xc2\\x85 you can\\'t help but fall in love.<br /><br />That\\'s why it was so hard for me to watch \"\\'Night, Mother.\" Spacek is wasted in a stilted stunt of a film that never serves to engage or even distract. I would not recommend this movie to anyone except die-hard fans of Sissy like myself and even then you\\'ll be disappointed. I do give the film an entire letter grade bonus for the ending, which is courageous enough to let the lead character do what\\'s right for *her* and not pander to a hackneyed happy ending. GRADE: C'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_instances[0].features.feature['text'].bytes_list.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14a9612e-0958-4803-85bf-6bb1efe26fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_instance(raw_record, key):\n",
    "    text_bytes = raw_record.features.feature['text'].bytes_list.value[0]\n",
    "    return { 'values': text_bytes, 'key': key }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a234083-512f-40ba-860f-c892284f6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = {'instances': [to_instance(v, k) for k, v in enumerate(raw_instances)]}\n",
    "\n",
    "instances = [ list(vectorizer(test_text).numpy()) ] # should be: list of examples, each example is a vector that is the output of the Vectorizer after processing a review\n",
    "\n",
    "#instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd6e3d3-4db2-4129-8d9a-bf20e51a05c8",
   "metadata": {},
   "source": [
    "## Test saving/loading Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef3b9161-37b1-4117-b31b-13c08f78826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer: TextVectorization = layers.TextVectorization(ngrams=2, max_tokens=20000, output_mode=\"multi_hot\")\n",
    "vectorizer.adapt(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "139b6ae1-a7ba-40a1-89ed-381f2a7b07ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-28 16:02:41.313806: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://ihr-vertex-pipelines/tmp/vectorizer/assets\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorizer)\n",
    "\n",
    "model.save('gs://ihr-vertex-pipelines/tmp/vectorizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3eff754c-b52f-4c47-8538-a4465589915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "restored_model = load_model('gs://ihr-vertex-pipelines/tmp/vectorizer/')\n",
    "restored_vectorizer = restored_model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4f01e84-3baa-4ebb-8d0b-d0ec17549ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "vectorizer(test_text).numpy()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8600b86a-b07a-457e-bcf1-2e0ccef6230a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20000,), dtype=float32, numpy=array([1., 1., 0., ..., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_vectorizer(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f05fc75e-c8e6-4fbd-a76d-6fde1fef40c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_vectorizer(test_text).numpy()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1d1ec48-86e6-457f-a263-e969cd16e8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization_2',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (),\n",
       " 'dtype': 'string',\n",
       " 'max_tokens': 20000,\n",
       " 'standardize': 'lower_and_strip_punctuation',\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': 2,\n",
       " 'output_mode': 'multi_hot',\n",
       " 'output_sequence_length': None,\n",
       " 'pad_to_max_tokens': False,\n",
       " 'sparse': False,\n",
       " 'ragged': False,\n",
       " 'vocabulary': None,\n",
       " 'idf_weights': None}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa05f26e-0ef0-484c-b108-1b24ce93906e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization_2',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (),\n",
       " 'dtype': 'string',\n",
       " 'max_tokens': 20000,\n",
       " 'standardize': 'lower_and_strip_punctuation',\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': 2,\n",
       " 'output_mode': 'multi_hot',\n",
       " 'output_sequence_length': None,\n",
       " 'pad_to_max_tokens': False,\n",
       " 'sparse': False,\n",
       " 'ragged': False,\n",
       " 'vocabulary': None,\n",
       " 'idf_weights': None}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91a6b1-25c6-4b04-b4ce-224ebae018b9",
   "metadata": {},
   "source": [
    "## Raw model load and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cc6b2-c0b8-4cda-9fad-19a75a509927",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel = load_model(model_location + 'saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b71d08d3-1fee-4c0e-a5a3-74d181a8b750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'my-kschool-model',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 20000),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_1'},\n",
       "   'name': 'input_1',\n",
       "   'inbound_nodes': []},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 16,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'name': 'dense',\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None},\n",
       "   'name': 'dropout',\n",
       "   'inbound_nodes': [[['dense', 0, 0, {}]]]},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'name': 'dense_1',\n",
       "   'inbound_nodes': [[['dropout', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['dense_1', 0, 0]]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasmodel.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5e5d8091-c25b-4010-8c82-037dab4180fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5589698 ],\n",
       "       [0.43218794],\n",
       "       [0.46867135]], dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = vectorizer(\"bad\")\n",
    "reviews = [\"great movie\", \"bad movie\", \"sucks\"]\n",
    "vects = [restored_vectorizer(x).numpy() for x in reviews]\n",
    "\n",
    "# convert input to numpy array and put into list (2-dim array actually)\n",
    "examples = np.array(vects)\n",
    "kerasmodel.predict(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6a73403e-7a9c-48b2-8d86-8dfe2d6a4e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (20000,), types: tf.float32>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_input = raw_dataset.map(lambda x: vectorizer(x))\n",
    "vectorized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a0908638-d50a-435b-b17b-33a221b6d4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20000), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"my-kschool-model\" (type Functional).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1/2690474634.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkerasmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"my-kschool-model\" (type Functional).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "kerasmodel.predict(vectorized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "db360192-4b8a-4bdf-8511-0c454e727ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (20000,), types: tf.float32>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [\"great movie\", \"bad movie\", \"sucks\"]\n",
    "vects = [vectorizer(x) for x in reviews]\n",
    "tf.data.Dataset.from_tensor_slices((vects))\n",
    "#kerasmodel.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6aa11-d6d6-452f-8b0c-2621a4077f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "managed-notebooks.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu:latest"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
